{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11941b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Self-Supervised Learning:\n",
    "Question: Can we learn meaningful representations of weather patterns in different cities using only the input data without labeled examples?\n",
    "Model: Autoencoder\n",
    "5. Multi-Instance Learning:\n",
    "Question: Can we predict if a city will experience extreme weather events (e.g., storms, heatwaves) based on multiple instances of weather data from different time periods?\n",
    "Model: Multi-Instance Support Vector Machine (MI-SVM)\n",
    "6. Inductive Learning:\n",
    "Question: Can we learn a general model to predict temperature in multiple cities based on their humidity, wind speed, wind direction, and pressure?\n",
    "Model: Random Forest or Gradient Boosting Machines\n",
    "7. Deductive Inference:\n",
    "Question: Based on a set of predefined rules, can we infer the weather patterns in different cities?\n",
    "Model: Rule-based Expert System\n",
    "8. Transductive Learning:\n",
    "Question: Can we predict the temperature for a specific day in City A without learning a general model?\n",
    "Model: Transductive Support Vector Machines\n",
    "9. Multi-Task Learning:\n",
    "Question: Can we simultaneously predict the temperature and humidity in City A for the next day based on its wind speed, wind direction, and pressure?\n",
    "Model: Multi-task Elastic Net\n",
    "10. Active Learning:\n",
    "Question: Can we iteratively improve the temperature prediction model for City A by querying an oracle for labels on the most informative data points?\n",
    "Model: Query-by-Committee or Uncertainty Sampling\n",
    "11. Online Learning:\n",
    "Question: Can we update the temperature prediction model for City A as new data arrives without retraining the model from scratch?\n",
    "Model: Online Gradient Descent or Online SVM\n",
    "12. Transfer Learning:\n",
    "Question: Can we improve the temperature prediction model for City B by leveraging the knowledge from the model trained on City A?\n",
    "Model: Domain Adaptation or Feature Representation Transfer\n",
    "13. Supervised Learning - Text Generation:\n",
    "Question: Given a row of weather data, can you generate a human-readable text description summarizing the weather conditions for that day?\n",
    "Model: Natural Language Processing\n",
    "Package for Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e8430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a2e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Implementation\n",
    "#Calling the build function to produce specs for the build\n",
    "best_hyperparams, best_mae, best_model, best_history, results = the_build(X, y, hyperparameters_list, cv_methods, input_steps, output_steps)\n",
    "# Print the best hyperparameters and MAE\n",
    "print(f\"\\nBest Hyperparameters: {best_hyperparams}\")\n",
    "print(f\"Best MAE: {best_mae}\")\n",
    "# Split the data into training and validation sets\n",
    "train_size = int(0.8 * len(data))\n",
    "train, test = data[0:train_size], data[train_size:]\n",
    "The Model\n",
    "\n",
    "# Train the final model using the best hyperparameters on the full training set\n",
    "X_train, y_train = to_supervised(train, best_hyperparams['input_steps'], best_hyperparams['output_steps'])\n",
    "final_model, final_history = create_lstm_model(X_train, y_train, best_hyperparams['lstm_units'], best_hyperparams['batch_size'],\n",
    "                                               best_hyperparams['epochs'], best_hyperparams['learning_rate'],\n",
    "                                               best_hyperparams['regularization'], best_hyperparams['dropout'],\n",
    "                                               best_hyperparams['early_stopping_patience'], best_hyperparams['activation'],\n",
    "                                               best_hyperparams['data_augmentation'], best_hyperparams['ensembling'],\n",
    "                                               best_hyperparams['pruning'])\n",
    "4. Model Evaluation:\n",
    "Testing\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "X_test, y_test = to_supervised(test, best_hyperparams['input_steps'], best_hyperparams['output_steps'])\n",
    "y_pred = final_model.predict(X_test)\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "print('Test MAE:', test_mae)\n",
    "Evaluate Preformance on the Testing Data\n",
    "\n",
    "Plotting Actual Vs. Predicted\n",
    "conda install -c conda-forge plotnine\n",
    "conda install -c conda-forge gganimate\n",
    "from plotnine import *\n",
    "from plotnine.data import mpg\n",
    "from ggplot import ggplot\n",
    "​\n",
    "# Create a sample data frame with actual and predicted values\n",
    "data = pd.DataFrame({'time': range(len(y_test)), 'actual': y_test, 'predicted': y_pred.flatten()})\n",
    "​\n",
    "# Create the ridge plot with actual and predicted values\n",
    "plot = (ggplot(data, aes(x='value', y='time', group='variable', fill='variable'))\n",
    "        + geom_density_ridges(alpha=0.5, scale=3, rel_min_height=0.03)\n",
    "        + scale_fill_manual(values=(\"#008080\", \"#FFA500\"))\n",
    "        + labs(x=\"Value\", y=\"Time\")\n",
    "        + ggtitle(\"Actual vs. Predicted Values\")\n",
    "        + transition_time(\"time\")\n",
    "        + ease_aes('linear'))\n",
    "​\n",
    "# Save the animated plot as a gif\n",
    "anim = plot.animate(interval=100, nframes=len(y_test))\n",
    "anim.save('animated_ridge.gif', writer='imagemagick')\n",
    "Evaluate the performance of the model on the testing data.\n",
    "# Evaluate the model with other metrics\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_absolute_error(y_test, y_pred)\n",
    "print('Test MAE: %.3f' % mae)\n",
    "b. Evaluate the model's performance considering operational requirements (i.e., operating reserve requirements).\n",
    "Conclusions and Insights\n",
    "\n",
    "5. Model Deployment:\n",
    "The new model tested automatically the same way always, and the author is not able to affect that. Metrics calculated automatically. It’s a good idea to display them on some dashboard where everybody in the team can view it. Based on the successful testing Pull-request with a new model can be accepted to join develop-branch and proceed for the next step.\n",
    "\n",
    "c. PI Historian: PI Historian is a data archiving and management system developed by OSIsoft. It is designed to collect, store, and manage large volumes of time-series data from various sources, including SCADA systems, PLCs, or other sensors. PI Historian provides tools for data analysis, reporting, and visualization, enabling users to monitor and analyze historical and real-time data efficiently. In your project, PI Historian could be a source of historical weather data, as well as a system for archiving and managing the data used to train and evaluate your models.\n",
    "\n",
    "4. A/B test\n",
    "3 steps above will allow you to gain you pretty good confidence in your new model. In some cases A/B test is not possible so you could stop on the shadow testing, some companies can afford to experiment with many different models at the same time, in that cases, shadow testing can be unnecessary and after testing on out-of-sample data model can be tested as part of A/B test.\n",
    "3. Stage testing / Shadow testing\n",
    "The next step is to test your model in the production-like environment. For example, we would deploy develop branch on the stage-server and make it run on the exact same data as production pipeline, the only difference would be that the end-user will not see the results of the develop-branch and results will be stored in the database. There are several questions you would wanna answer before running such an experiment, but the main one is:\n",
    "​\n",
    "— “When do I stop that experiment?”\n",
    "​\n",
    "Similar to A/B testing to answer that you need to figure out the effect size you expected to capture and statistical power.\n",
    "​\n",
    "To make final conclusion about model quality I suggest you use a statistical test to protect yourself from being fulled by randomness, but keep in mind it’s not 100% robust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba3d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "Write report and explain the descisions and made- use and application- insights provided and data based decision making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf291063",
   "metadata": {},
   "outputs": [],
   "source": [
    "Package and deploy for production- how can this model be used for other purposes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Make Presention and Report\n",
    "Power Bi and Tableau?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7662e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Find ways to include tools from other job requisitions- then edit display and highlights of work according to job requisitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e313a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Start on other types of models- make one of each type"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
